{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "import numpy\n",
    "from matplotlib.pylab import *\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from utils.printProgressBar import printProgressBar\n",
    "\n",
    "def echo(txt):\n",
    "    sys.stdout.write('\\r {}'.format(txt))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def getNumTrainParms(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return params\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples in vis. input: 824\n",
      "Shape of visual input: (32, 32, 3)\n",
      "Shape of right speeds: 824\n",
      "Shape of left  speeds: 824\n"
     ]
    }
   ],
   "source": [
    "# READ IN THE TRAINING DATA:\n",
    "\n",
    "f = open('robo_data_persp.pickle', 'rb')\n",
    "dat = pickle.load(f)\n",
    "IMG = dat['IMG']\n",
    "v_left = dat['LEFT_V']\n",
    "v_right = dat['RIGHT_V']\n",
    "\n",
    "trgRes = (32, 32)\n",
    "for i in range(len(IMG)):\n",
    "    IMG[i] = cv2.resize(IMG[i], dsize=trgRes, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "print('Samples in vis. input: {}'.format(IMG.__len__()))\n",
    "print('Shape of visual input: {}'.format(IMG[0].shape))\n",
    "\n",
    "print('Shape of right speeds: {}'.format(v_right.__len__()))\n",
    "print('Shape of left  speeds: {}'.format(v_left.__len__()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visual input shape: (824, 1, 32, 32)\n",
      "Visual target shape: torch.Size([824, 1, 32, 32])\n",
      "Motor target shape: torch.Size([824, 2])\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# prep the data:\n",
    "\n",
    "v_right = dat['RIGHT_V']\n",
    "v_left = dat['LEFT_V']\n",
    "img = np.stack(IMG)\n",
    "img = img.transpose(0,3,1,2)\n",
    "img = img[:,0,:,:]\n",
    "img = img[:,None, :,:]\n",
    "visual_input = torch.tensor(img, dtype=torch.float)\n",
    "\n",
    "visual_target = np.roll(visual_input, -1, axis=0)\n",
    "visual_target = torch.tensor(visual_target, dtype=torch.float)\n",
    "\n",
    "target_v_right = np.roll(v_right, -1, axis=0)\n",
    "target_v_left  = np.roll(v_left, -1, axis=0)\n",
    "\n",
    "v_right = torch.tensor(v_right, dtype=torch.float).view(-1,1)\n",
    "v_left = torch.tensor(v_left, dtype=torch.float).view(-1,1)\n",
    "\n",
    "target_v_right = torch.tensor(target_v_right, dtype=torch.float).view(-1,1)\n",
    "target_v_left = torch.tensor(target_v_left, dtype=torch.float).view(-1,1)\n",
    "\n",
    "motor_input = torch.cat((v_right, v_left), dim=1)\n",
    "motor_target = torch.cat((target_v_right, target_v_left), dim=1)\n",
    "\n",
    "\n",
    "print('Visual input shape: {}'.format(img.shape))\n",
    "print('Visual target shape: {}'.format(visual_target.shape))\n",
    "print('Motor target shape: {}'.format(motor_target.shape))\n",
    "\n",
    "# check in the inputs have really been rolled as needed:\n",
    "print([torch.sum(visual_input[i+1] - visual_target[i]).item() for i in range(10)])\n",
    "print([torch.sum(motor_input[i+1] - motor_target[i]).item() for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12e287860>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# us1 =   nn.Upsample(scale_factor=10, mode='nearest', align_corners=None)\n",
    "us1 =   nn.MaxPool2d(2, stride=2, padding=1)\n",
    "us2 =   nn.AvgPool2d(2, stride=2, padding=1)\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(visual_input[1].squeeze().detach().numpy())\n",
    "plt.subplot(1,3,2)\n",
    "x = us1(visual_input[1].unsqueeze(0)).squeeze().detach().numpy()\n",
    "x1 = us2(visual_input[1].unsqueeze(0)).squeeze().detach().numpy()\n",
    "plt.imshow(x)\n",
    "plt.title(x.shape)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, cell_type, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()                  # extend the functionality of previously built classes.\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell_type = cell_type\n",
    "        # YOU CAN USE EITHER LSTM, GRU OR VANILLA RNN\n",
    "        if self.cell_type=='GRU':\n",
    "            self.rnn_cell = nn.GRU(input_size=input_size,    # the dimensionality of ONE ELEMENT in a sequence\n",
    "                                hidden_size=hidden_size, # apparently the hidden state and output dimensionality must be the same\n",
    "                                num_layers=1)            # how many LSTM cells we want to stack (defalult=1)\n",
    "        if self.cell_type=='LSTM':\n",
    "            self.rnn_cell = nn.LSTM(input_size=input_size,    # the dimensionality of ONE ELEMENT in a sequence\n",
    "                                hidden_size=hidden_size, # apparently the hidden state and output dimensionality must be the same\n",
    "                                num_layers=1)            # how many LSTM cells we want to stack (defalult=1)\n",
    "        if self.cell_type=='RNN':\n",
    "            self.rnn_cell = nn.RNN(input_size=input_size,    # the dimensionality of ONE ELEMENT in a sequence\n",
    "                                hidden_size=hidden_size, # apparently the hidden state and output dimensionality must be the same\n",
    "                                num_layers=1)            # how many LSTM cells we want to stack (defalult=1)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 7, kernel_size=3, padding=(1,1))\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(7, 28, 3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2)\n",
    "        self.fc1 =   nn.Linear(1792, 100)\n",
    "        self.fc2 =   nn.Linear(100, 10)\n",
    "        self.fc3 =   nn.Linear(12, 2) # latent video (10) + motor (2) output from RNN to motor prediction\n",
    "        self.fc4 =   nn.Linear(12, 64)\n",
    "        self.us1 =   nn.Upsample(scale_factor=2, mode='nearest', align_corners=None)\n",
    "        self.us2 =   nn.Upsample(scale_factor=2, mode='nearest', align_corners=None)\n",
    "        self.us3 =   nn.Upsample(scale_factor=2, mode='nearest', align_corners=None)\n",
    "        self.us4 =   nn.Upsample(scale_factor=2, mode='nearest', align_corners=None)\n",
    "        self.conv3 = nn.Conv2d(1, 10, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(10, 1, 3, padding=1)\n",
    "        self.activate = nn.Tanh()\n",
    "        self.optimizer = optim.RMSprop(self.parameters(),\n",
    "                                       lr=0.001,\n",
    "                                       momentum=0.00,\n",
    "                                       weight_decay=0.000,\n",
    "                                       centered=False)\n",
    "        \n",
    "        \n",
    "    def forward(self, visual_input, motor_input, hidden):\n",
    "        \n",
    "        # visual pathway:\n",
    "        out = F.relu(self.conv1(visual_input))\n",
    "        out = self.pool1(out)\n",
    "        out = F.relu(self.conv2(out)) # torch.Size([1367, 15, 58, 58])\n",
    "        out = self.pool2(out)         # torch.Size([1367, 15, 28, 28])\n",
    "        out = out.view(-1, out.size()[1]*out.size()[2]*out.size()[3]) # flatten\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        \n",
    "        # concatenate visual pathway and motor input:\n",
    "        out = torch.cat((out, motor_input), dim=1).unsqueeze_(1) # unsqueeze adds a dimension (for batch=1) inplace\n",
    "        \n",
    "        # run this combined input through an RNN cell (to predict the next visual input and motor state):\n",
    "        out, hidden = self.rnn_cell(out, hidden)\n",
    "        \n",
    "        # predict motor output based on the latent representation:\n",
    "        motor_output = F.relu(self.fc3(out.squeeze()))\n",
    "        \n",
    "        # reconstruct video from the latent representation:\n",
    "        out1 = F.relu(self.fc4(out.squeeze()))\n",
    "        out1 = out1.view(-1,1,8,8)\n",
    "        out1 = self.us1(out1)\n",
    "        out1 = F.relu(self.conv3(out1))\n",
    "        out1 = self.us2(out1)\n",
    "        out1 = F.relu(self.conv4(out1))\n",
    "\n",
    "        return out1, motor_output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        if self.cell_type=='LSTM': # we initialize a 2-tuple of hidden states (hidden state, memory)\n",
    "            return (torch.zeros(1, 1, self.hidden_size), torch.zeros(1, 1, self.hidden_size))\n",
    "        if self.cell_type=='GRU' or self.cell_type=='RNN': # we initialize a hidden state\n",
    "            return torch.zeros(1, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn.optimizer.zero_grad()\n",
    "# hidden = rnn.initHidden()\n",
    "# out, hidden = rnn(visual_input, motor_input, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size  = 12\n",
    "hidden_size = 12\n",
    "output_size = 12\n",
    "cell_type = 'GRU'\n",
    "\n",
    "EPOCHS = 5000\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "rnn = RNN(cell_type, input_size, hidden_size, output_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For optimal results, see when motor loss stops decreasing, interrupt the training, increase the weight of the motor loss and continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 vloss: 12741.60 mloss: 54.06 Progress:  |--------------------------------------------------| 0.3% Complete"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4d30ae51d476>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# re-init hidden state to zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvisual_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmotor_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisual_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmotor_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmotor_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmotor_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmotor_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mvisual_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisual_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisual_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-25e7d0df15f0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, visual_input, motor_input, hidden)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# visual pathway:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisual_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# torch.Size([1367, 15, 58, 58])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    338\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    339\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 340\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LOSS = []\n",
    "printProgressBar(0, EPOCHS, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
    "for epoch in range(EPOCHS):\n",
    "    rnn.optimizer.zero_grad()\n",
    "    hidden = rnn.initHidden() # re-init hidden state to zero\n",
    "    visual_output, motor_output, hidden = rnn(visual_input, motor_input, hidden)\n",
    "    motor_loss = 1 * criterion(motor_output, motor_target)\n",
    "    visual_loss = criterion(visual_output, visual_target)\n",
    "    loss = motor_loss + visual_loss\n",
    "    loss.backward()\n",
    "    LOSS.append(loss.item())\n",
    "    rnn.optimizer.step()\n",
    "    printProgressBar(epoch + 1, EPOCHS, prefix='Epoch: {} vloss: {:.2f} mloss: {:.2f} Progress: '.format(\n",
    "        epoch, visual_loss.item(), motor_loss.item()), suffix='Complete', length=50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
